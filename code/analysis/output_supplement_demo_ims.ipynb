{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create letter demos for supp\n",
    "\n",
    "This notebook relies on version 1.3.1 of Tom's `psyutils` package (unlike Saskia's code, which uses v.0.1.1 [available from Github]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import color, io, img_as_float, transform\n",
    "import pandas as pd\n",
    "import psyutils as pu\n",
    "from psyutils.image import show_im\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# # set some styles we like:\n",
    "# sns.set_style(\"white\")\n",
    "# sns.set_style(\"ticks\")\n",
    "# sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed:\n",
    "rng = np.random.RandomState(seed = 22239217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_dir = \"/Users/tomwallis/Dropbox/Projects/letter-distortion-detection\"\n",
    "out_dir = os.path.join(top_dir, 'results', 'supplementary_ims')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for making letter images and distorting them\n",
    "\n",
    "Here I duplicate the stimulus generation code for distortion from Saskia's scripts (see `experiment1.py`), updated to the latest version of psyutils (e.g. replaced `make_filter` with `make_filter_log_exp`, changed norming of filter to match old code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bex_distorted_im(im, amplitude=2, frequency=4):\n",
    "    \"\"\"A spatial distortion method based on a method by Peter Bex (see ref, below).\n",
    "\n",
    "    Args:\n",
    "        im (float): the image to distort.\n",
    "        amplitude (int): determines the amplitude of distortion in pixels.\n",
    "        frequency (int): peak frequency of the filter.\n",
    "    Returns:\n",
    "        dist_image (float): the distorted image.\n",
    "\n",
    "    Example:\n",
    "        Distort an image:\n",
    "            im = img_as_float(pu.im_data.tiger_grey())\n",
    "            scale = 5\n",
    "            f_peak = 4\n",
    "            dist_im = bex_distorted_im(im, scale, f_peak) \n",
    "            pu.image.show_im(dist_im)\n",
    "\n",
    "    Reference:\n",
    "        Bex, P. J. (2010). (In) sensitivity to spatial distortion in natural\n",
    "        scenes. Journal of Vision, 10(2), 23:1-15.\n",
    "\n",
    "    \"\"\"\n",
    "    # log-exponential filter to create random-bandpass filtered noise samples as positional offset\n",
    "    filt = pu.image.make_filter_log_exp(size=im.shape[0], \n",
    "                                        peak=frequency, \n",
    "                                        width=0.5)\n",
    "    \n",
    "    # cosine window that reduces to zero over the padding region \n",
    "    cos_win = pu.image.cos_win_2d(size=im.shape[0], ramp=14, \n",
    "                                  ramp_type = \"pixels\")\n",
    "\n",
    "\n",
    "    # old version of psyutils (used in sakia's code) scales filtered noise\n",
    "    # to have max absolute value of 1. Do this manually here:\n",
    "    filtered_noise_x = pu.image.make_filtered_noise(filt, rng)\n",
    "    filtered_noise_y = pu.image.make_filtered_noise(filt, rng)\n",
    "    \n",
    "    filtered_noise_x = filtered_noise_x / abs(filtered_noise_x).max()\n",
    "    filtered_noise_y = filtered_noise_y / abs(filtered_noise_y).max()\n",
    "\n",
    "    # horizontal and vertical positional offset \n",
    "    filt_noise_x = filtered_noise_x * cos_win * amplitude\n",
    "    filt_noise_y = filtered_noise_y * cos_win * amplitude\n",
    "    \n",
    "    # disort image \n",
    "    dist_im = pu.image.grid_distort(im, x_offset=filt_noise_x, y_offset=filt_noise_y, \n",
    "                                   method=\"linear\", fill_method=1)\n",
    "    return(dist_im)\n",
    "\n",
    "\n",
    "def rf_distorted_im(im, amplitude=0.1, frequency=3):\n",
    "    \"\"\"Creates a radial frequency modulated grid by modulating the distance from the center to every point \n",
    "    sinusoidally with a certain amplitude and frequency\n",
    "    \n",
    "    Based on a method by Dickinson et al. (see ref, below). \n",
    "\n",
    "    Args:\n",
    "        im (float): the image to distort.\n",
    "        amplitude (float): modulation amplitude, expressed as a proportion of the distance from the center of the \n",
    "                   unmodulated radius\n",
    "        frequency (int): the frequency of modulation in 2*pi radians\n",
    "        \n",
    "    Returns:\n",
    "        dist_image (float): the distorted image.\n",
    "\n",
    "    Example:\n",
    "        Distort an image:\n",
    "            im = img_as_float(pu.im_data.tiger_grey())\n",
    "            amplitude = 0.2\n",
    "            frequency = 5\n",
    "            dist_im = rf_distorted_im(im, amplitude, frequency) \n",
    "            pu.image.show_im(dist_im)\n",
    "\n",
    "    Reference:\n",
    "        Dickinson, J. E., Almeida, R. A., Bell, J. & Badcock, D. R. (2010). Global shape aftereffects have a local substrate: \n",
    "        A tilt aftereffect field. Journal of Vision,10 (13), 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # get radial distance \n",
    "    x = np.linspace(-20, 20, num=im.shape[0])\n",
    "    xx, yy = np.meshgrid(x, x)    \n",
    "    rad_dist = (xx**2 + yy**2)**0.5\n",
    "    \n",
    "    # randomise phase \n",
    "    rand_num = rng.rand()*2*np.pi\n",
    "\n",
    "    # angular distance\n",
    "    ang_dist = ((rand_num+np.arctan2(xx, -yy))%(2*np.pi))-np.pi\n",
    " \n",
    "    # modulate distance of each point from the center sinusoidally (cf. Dickinson et al. p. 3)\n",
    "    rf_grid = rad_dist*(1+amplitude*(np.sin(frequency*ang_dist)))\n",
    "    \n",
    "    # calculate radial distance offset for each point\n",
    "    delta_rad = rf_grid - rad_dist\n",
    "   \n",
    "    # cosine window that reduces to zero over the padding region \n",
    "    cos_win = pu.image.cos_win_2d(size=im.shape[0], ramp=14,\n",
    "                                  ramp_type=\"pixels\")\n",
    "    \n",
    "    # convert from polar to cartesian coordinates \n",
    "    x_offset = delta_rad * np.cos(ang_dist) * cos_win\n",
    "    y_offset = delta_rad * np.sin(ang_dist) * cos_win\n",
    "\n",
    "    # distort image\n",
    "    dist_im = pu.image.grid_distort(im, x_offset=x_offset, y_offset=y_offset, \n",
    "                                   method=\"linear\", fill_method=1)\n",
    "    return(dist_im)\n",
    "\n",
    "\n",
    "def undistorted_letter(letter):\n",
    "    \"\"\"\n",
    "    Return the undistorted sloan letter with appropriate padding as used in the experiment.\n",
    "    \n",
    "    \"\"\"\n",
    "    letter_dict = pu.im_data.sloan_letters()\n",
    "    im = letter_dict[letter]\n",
    "\n",
    "    # resize letter to have a padding area of 14 pixels at each side\n",
    "    im = transform.resize(im, (64, 64))\n",
    "    pad = np.ones((92,92))\n",
    "    im = pu.image.put_rect_in_rect(im, pad)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which frequencies and amplitudes to test?\n",
    "\n",
    "We wish to examine whether\n",
    "\n",
    "1. different patterns of sensitivity for BPN and RF distortions could be explained by similar falloffs in spatial frequency or orientation energy\n",
    "2. differences in letter performance could be explained similarly\n",
    "\n",
    "To do this, I will \n",
    "\n",
    "1. take the mean threshold values from Experiment 1 in each of flanked / unflanked, BPN / RF, each frequency of distortion\n",
    "2. compute the spectra for each undistorted letter, and for each letter with each threshold level of distortion. Distortions will be repeated some number of times to get an idea of the average effect of distortions.\n",
    "3. Plot the spectra differences for each condition (passed to R for plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(top_dir, \"results\", \"r-analysis-final-paper\", \"expt_1_thresholds.csv\")\n",
    "thresh_dat = pd.read_csv(fname)\n",
    "thresh_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_threshs = thresh_dat.groupby([\"flanked\", \"freq\", \"distortion\"]).threshold.mean()\n",
    "mean_threshs = pd.DataFrame(mean_threshs)\n",
    "mean_threshs.reset_index(inplace=True)\n",
    "print(mean_threshs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In the BPN distortion type, thresholds are in units of degrees (representing the amplitude of the shift in pixels -- see `/code/analysis/getpsignifitdata.m` line 107. Below I correct *back* to pixels to ensure that the shift is correct for applying the distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a third threshold level to the data above, representing the largest distortion \n",
    "# we applied:\n",
    "extra_level_1 = pu.psydata.expand_grid({\"flanked\": [\"max\"],\n",
    "                                        \"freq\": np.unique(mean_threshs[mean_threshs[\"distortion\"]==\"BPN\"].freq),\n",
    "                                        \"distortion\": [\"BPN\"]})\n",
    "extra_level_1[\"threshold\"] = 5 / 41.5  # largest threshold used for BPN\n",
    "\n",
    "extra_level_2 = pu.psydata.expand_grid({\"flanked\": [\"max\"],\n",
    "                                        \"freq\": np.unique(mean_threshs[mean_threshs[\"distortion\"]==\"RF\"].freq),\n",
    "                                        \"distortion\": [\"RF\"]})\n",
    "extra_level_2[\"threshold\"] = 0.32\n",
    "\n",
    "mean_threshs = mean_threshs.append(extra_level_1, ignore_index = True)\n",
    "mean_threshs = mean_threshs.append(extra_level_2, ignore_index = True)\n",
    "mean_threshs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over conditions\n",
    "\n",
    "Create a big image for each distortion type, threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_im = undistorted_letter(\"K\")\n",
    "show_im(test_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = [\"K\", \"H\", \"D\", \"N\"]\n",
    "im_r = test_im.shape[0]\n",
    "im_c = test_im.shape[1]\n",
    "\n",
    "for dist, flank in product(np.unique(mean_threshs[\"distortion\"]), \n",
    "                           np.unique(mean_threshs[\"flanked\"])):\n",
    "    \n",
    "    df = mean_threshs.loc[(mean_threshs[\"distortion\"] == dist) &\n",
    "                           (mean_threshs[\"flanked\"] == flank)]\n",
    "    \n",
    "    big_im = np.zeros((len(letters) * im_r,\n",
    "                       len(np.unique(df[\"freq\"])) * im_c))\n",
    "\n",
    "    i_r = 0\n",
    "    i_c = 0\n",
    "    \n",
    "    for letter in letters:\n",
    "        im = undistorted_letter(letter)\n",
    "        \n",
    "        for freq in np.unique(df[\"freq\"]):\n",
    "            thresh = df.loc[df[\"freq\"] == freq, \"threshold\"].values\n",
    "            px_thresh = thresh * 41.5  # see comment above: thresholds --> pixel units        \n",
    "            \n",
    "            if dist == \"BPN\":\n",
    "                d_im = bex_distorted_im(im, amplitude=px_thresh, frequency=freq)\n",
    "            elif dist == \"RF\":\n",
    "                d_im = rf_distorted_im(im, amplitude=thresh, frequency=freq)\n",
    "            else:\n",
    "                raise ValueError(\"distortion not known\")\n",
    "            \n",
    "            # add distorted image to big im:\n",
    "            big_im[i_r : i_r + im_r,\n",
    "                   i_c : i_c + im_c] = d_im\n",
    "            \n",
    "            # increment cols for each freq:\n",
    "            i_c += im_c\n",
    "        \n",
    "        # increment rows for each letter:\n",
    "        i_r += im_r\n",
    "        i_c = 0\n",
    "    \n",
    "    # save big im:\n",
    "    fname = os.path.join(out_dir,\n",
    "                         \"{}_{}.png\".format(\n",
    "            dist, flank))\n",
    "    io.imsave(fname, big_im)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
