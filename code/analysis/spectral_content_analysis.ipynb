{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of spectral content of letter distortions\n",
    "\n",
    "The following notebook quantifies the changes in the spatial and orientation energy caused by applying (1) Bandpass Noise and (2) Radial Frequency distortions to Sloan letters. It accompanies the paper \n",
    "\n",
    "Wallis, Tobias, Bethge & Wichmann (under review). Detecting distortions of peripherally-presented letter stimuli under crowded conditions.\n",
    "\n",
    "This notebook relies on version 1.3.1 of Tom's `psyutils` package (unlike Saskia's code, which uses v.0.1.1 [available from Github]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import color, io, img_as_float, transform\n",
    "import pandas as pd\n",
    "import psyutils as pu\n",
    "from psyutils.image import show_im\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# # set some styles we like:\n",
    "# sns.set_style(\"white\")\n",
    "# sns.set_style(\"ticks\")\n",
    "# sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed:\n",
    "rng = np.random.RandomState(seed = 22239217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_dir = \"/Users/tomwallis/Dropbox/Projects/letter-distortion-detection\"\n",
    "out_dir = os.path.join(top_dir, 'results', 'spectral_analysis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for making letter images and distorting them\n",
    "\n",
    "Here I duplicate the stimulus generation code for distortion from Saskia's scripts (see `experiment1.py`), updated to the latest version of psyutils (e.g. replaced `make_filter` with `make_filter_log_exp`, changed norming of filter to match old code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bex_distorted_im(im, amplitude=2, frequency=4):\n",
    "    \"\"\"A spatial distortion method based on a method by Peter Bex (see ref, below).\n",
    "\n",
    "    Args:\n",
    "        im (float): the image to distort.\n",
    "        amplitude (int): determines the amplitude of distortion in pixels.\n",
    "        frequency (int): peak frequency of the filter.\n",
    "    Returns:\n",
    "        dist_image (float): the distorted image.\n",
    "\n",
    "    Example:\n",
    "        Distort an image:\n",
    "            im = img_as_float(pu.im_data.tiger_grey())\n",
    "            scale = 5\n",
    "            f_peak = 4\n",
    "            dist_im = bex_distorted_im(im, scale, f_peak) \n",
    "            pu.image.show_im(dist_im)\n",
    "\n",
    "    Reference:\n",
    "        Bex, P. J. (2010). (In) sensitivity to spatial distortion in natural\n",
    "        scenes. Journal of Vision, 10(2), 23:1-15.\n",
    "\n",
    "    \"\"\"\n",
    "    # log-exponential filter to create random-bandpass filtered noise samples as positional offset\n",
    "    filt = pu.image.make_filter_log_exp(size=im.shape[0], \n",
    "                                        peak=frequency, \n",
    "                                        width=0.5)\n",
    "    \n",
    "    # cosine window that reduces to zero over the padding region \n",
    "    cos_win = pu.image.cos_win_2d(size=im.shape[0], ramp=14, \n",
    "                                  ramp_type = \"pixels\")\n",
    "\n",
    "\n",
    "    # old version of psyutils (used in sakia's code) scales filtered noise\n",
    "    # to have max absolute value of 1. Do this manually here:\n",
    "    filtered_noise_x = pu.image.make_filtered_noise(filt, rng)\n",
    "    filtered_noise_y = pu.image.make_filtered_noise(filt, rng)\n",
    "    \n",
    "    filtered_noise_x = filtered_noise_x / abs(filtered_noise_x).max()\n",
    "    filtered_noise_y = filtered_noise_y / abs(filtered_noise_y).max()\n",
    "\n",
    "    # horizontal and vertical positional offset \n",
    "    filt_noise_x = filtered_noise_x * cos_win * amplitude\n",
    "    filt_noise_y = filtered_noise_y * cos_win * amplitude\n",
    "    \n",
    "    # disort image \n",
    "    dist_im = pu.image.grid_distort(im, x_offset=filt_noise_x, y_offset=filt_noise_y, \n",
    "                                   method=\"linear\", fill_method=1)\n",
    "    return(dist_im)\n",
    "\n",
    "\n",
    "def rf_distorted_im(im, amplitude=0.1, frequency=3):\n",
    "    \"\"\"Creates a radial frequency modulated grid by modulating the distance from the center to every point \n",
    "    sinusoidally with a certain amplitude and frequency\n",
    "    \n",
    "    Based on a method by Dickinson et al. (see ref, below). \n",
    "\n",
    "    Args:\n",
    "        im (float): the image to distort.\n",
    "        amplitude (float): modulation amplitude, expressed as a proportion of the distance from the center of the \n",
    "                   unmodulated radius\n",
    "        frequency (int): the frequency of modulation in 2*pi radians\n",
    "        \n",
    "    Returns:\n",
    "        dist_image (float): the distorted image.\n",
    "\n",
    "    Example:\n",
    "        Distort an image:\n",
    "            im = img_as_float(pu.im_data.tiger_grey())\n",
    "            amplitude = 0.2\n",
    "            frequency = 5\n",
    "            dist_im = rf_distorted_im(im, amplitude, frequency) \n",
    "            pu.image.show_im(dist_im)\n",
    "\n",
    "    Reference:\n",
    "        Dickinson, J. E., Almeida, R. A., Bell, J. & Badcock, D. R. (2010). Global shape aftereffects have a local substrate: \n",
    "        A tilt aftereffect field. Journal of Vision,10 (13), 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # get radial distance \n",
    "    x = np.linspace(-20, 20, num=im.shape[0])\n",
    "    xx, yy = np.meshgrid(x, x)    \n",
    "    rad_dist = (xx**2 + yy**2)**0.5\n",
    "    \n",
    "    # randomise phase \n",
    "    rand_num = rng.rand()*2*np.pi\n",
    "\n",
    "    # angular distance\n",
    "    ang_dist = ((rand_num+np.arctan2(xx, -yy))%(2*np.pi))-np.pi\n",
    " \n",
    "    # modulate distance of each point from the center sinusoidally (cf. Dickinson et al. p. 3)\n",
    "    rf_grid = rad_dist*(1+amplitude*(np.sin(frequency*ang_dist)))\n",
    "    \n",
    "    # calculate radial distance offset for each point\n",
    "    delta_rad = rf_grid - rad_dist\n",
    "   \n",
    "    # cosine window that reduces to zero over the padding region \n",
    "    cos_win = pu.image.cos_win_2d(size=im.shape[0], ramp=14,\n",
    "                                  ramp_type=\"pixels\")\n",
    "    \n",
    "    # convert from polar to cartesian coordinates \n",
    "    x_offset = delta_rad * np.cos(ang_dist) * cos_win\n",
    "    y_offset = delta_rad * np.sin(ang_dist) * cos_win\n",
    "\n",
    "    # distort image\n",
    "    dist_im = pu.image.grid_distort(im, x_offset=x_offset, y_offset=y_offset, \n",
    "                                   method=\"linear\", fill_method=1)\n",
    "    return(dist_im)\n",
    "\n",
    "\n",
    "def undistorted_letter(letter):\n",
    "    \"\"\"\n",
    "    Return the undistorted sloan letter with appropriate padding as used in the experiment.\n",
    "    \n",
    "    \"\"\"\n",
    "    letter_dict = pu.im_data.sloan_letters()\n",
    "    im = letter_dict[letter]\n",
    "\n",
    "    # resize letter to have a padding area of 14 pixels at each side\n",
    "    im = transform.resize(im, (64, 64))\n",
    "    pad = np.ones((92,92))\n",
    "    im = pu.image.put_rect_in_rect(im, pad)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example spectral analysis using psyutils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = undistorted_letter(\"K\")\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1), plt.imshow(img, cmap='gray'), plt.axis('off')\n",
    "\n",
    "A, P, F = pu.image.spectral_analysis_fft(img)\n",
    "\n",
    "plt.subplot(1,3,2), plt.imshow(np.log(A), cmap='gray'), plt.axis('off')\n",
    "plt.subplot(1,3,3), plt.imshow(P, cmap='gray'), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pu.image.spectral_analysis(img)\n",
    "pu.image.spectral_analysis_plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example bpn distortion:\n",
    "d_im = bex_distorted_im(img, amplitude = 5, frequency=5)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1), plt.imshow(d_im, cmap='gray'), plt.axis('off')\n",
    "\n",
    "A, P, F = pu.image.spectral_analysis_fft(d_im)\n",
    "\n",
    "plt.subplot(1,3,2), plt.imshow(np.log(A), cmap='gray'), plt.axis('off')\n",
    "plt.subplot(1,3,3), plt.imshow(P, cmap='gray'), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pu.image.spectral_analysis(d_im)\n",
    "pu.image.spectral_analysis_plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example rf distortion:\n",
    "d_im = rf_distorted_im(img, amplitude = 0.32, frequency=2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1), plt.imshow(d_im, cmap='gray'), plt.axis('off')\n",
    "\n",
    "A, P, F = pu.image.spectral_analysis_fft(d_im)\n",
    "\n",
    "plt.subplot(1,3,2), plt.imshow(np.log(A), cmap='gray'), plt.axis('off')\n",
    "plt.subplot(1,3,3), plt.imshow(P, cmap='gray'), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pu.image.spectral_analysis(d_im)\n",
    "pu.image.spectral_analysis_plot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which frequencies and amplitudes to test?\n",
    "\n",
    "We wish to examine whether\n",
    "\n",
    "1. different patterns of sensitivity for BPN and RF distortions could be explained by similar falloffs in spatial frequency or orientation energy\n",
    "2. differences in letter performance could be explained similarly\n",
    "\n",
    "To do this, I will \n",
    "\n",
    "1. take the mean threshold values from Experiment 1 in each of flanked / unflanked, BPN / RF, each frequency of distortion\n",
    "2. compute the spectra for each undistorted letter, and for each letter with each threshold level of distortion. Distortions will be repeated some number of times to get an idea of the average effect of distortions.\n",
    "3. Plot the spectra differences for each condition (passed to R for plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(top_dir, \"results\", \"r-analysis-final-paper\", \"expt_1_thresholds.csv\")\n",
    "thresh_dat = pd.read_csv(fname)\n",
    "thresh_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_threshs = thresh_dat.groupby([\"flanked\", \"freq\", \"distortion\"]).threshold.mean()\n",
    "mean_threshs = pd.DataFrame(mean_threshs)\n",
    "mean_threshs.reset_index(inplace=True)\n",
    "print(mean_threshs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In the BPN distortion type, thresholds are in units of degrees (representing the amplitude of the shift in pixels -- see `/code/analysis/getpsignifitdata.m` line 107. Below I correct *back* to pixels to ensure that the shift is correct for applying the distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a third threshold level to the data above, representing the largest distortion \n",
    "# we applied:\n",
    "extra_level_1 = pu.psydata.expand_grid({\"flanked\": [\"max\"],\n",
    "                                        \"freq\": np.unique(mean_threshs[mean_threshs[\"distortion\"]==\"BPN\"].freq),\n",
    "                                        \"distortion\": [\"BPN\"]})\n",
    "extra_level_1[\"threshold\"] = 5 / 41.5  # largest threshold used for BPN\n",
    "\n",
    "extra_level_2 = pu.psydata.expand_grid({\"flanked\": [\"max\"],\n",
    "                                        \"freq\": np.unique(mean_threshs[mean_threshs[\"distortion\"]==\"RF\"].freq),\n",
    "                                        \"distortion\": [\"RF\"]})\n",
    "extra_level_2[\"threshold\"] = 0.32\n",
    "\n",
    "mean_threshs = mean_threshs.append(extra_level_1, ignore_index = True)\n",
    "mean_threshs = mean_threshs.append(extra_level_2, ignore_index = True)\n",
    "mean_threshs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean thresholds over frequencies:\n",
    "mean_threshs.groupby([\"flanked\", \"distortion\"]).threshold.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over conditions\n",
    "\n",
    "Saving results to a big dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def append_energy_results(sf_df, ori_df, res,\n",
    "                         letter_type, \n",
    "                         letter,\n",
    "                         flanked,\n",
    "                         freq, \n",
    "                         distortion,\n",
    "                         rep):\n",
    "    \"\"\" function to append the energy result res\n",
    "    to dataframe df.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # spatial freq\n",
    "    x = res['freq']\n",
    "    y = res['freq_amp']\n",
    "\n",
    "    this_df = pd.DataFrame({'letter_type': letter_type,\n",
    "                            'letter': letter,\n",
    "                            'flanked': flanked,\n",
    "                            'freq': freq,\n",
    "                            'distortion': distortion,\n",
    "                            'rep': rep,\n",
    "                            'x': x,\n",
    "                            'y': y})\n",
    "    sf_df = sf_df.append(this_df, ignore_index=True)\n",
    "    \n",
    "    # ori\n",
    "    x = res['ang']\n",
    "    y = res['ang_amp']\n",
    "\n",
    "    this_df = pd.DataFrame({'letter_type': letter_type,\n",
    "                            'letter': letter,\n",
    "                            'flanked': flanked,\n",
    "                            'freq': freq,\n",
    "                            'distortion': distortion,\n",
    "                            'rep': rep,\n",
    "                            'x': x,\n",
    "                            'y': y})\n",
    "    ori_df = ori_df.append(this_df, ignore_index=True)    \n",
    "    \n",
    "    return sf_df, ori_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = [\"K\", \"H\", \"D\", \"N\"]\n",
    "# letters = [\"K\"]\n",
    "reps = 15  # number of repetitions of distortions (to get average distortion effect).\n",
    "sf_energy = pd.DataFrame()\n",
    "ori_energy = pd.DataFrame()\n",
    "\n",
    "for letter in letters:\n",
    "    print(letter)\n",
    "    # do distortions:\n",
    "    for idx in range(len(mean_threshs)):\n",
    "        flank = mean_threshs.ix[idx, \"flanked\"]\n",
    "        freq = mean_threshs.ix[idx, \"freq\"]\n",
    "        dist = mean_threshs.ix[idx, \"distortion\"]\n",
    "        thresh = mean_threshs.ix[idx, \"threshold\"]\n",
    "        px_thresh = thresh * 41.5  # see comment above: thresholds --> pixel units        \n",
    "\n",
    "        im = undistorted_letter(letter)\n",
    "        res = pu.image.spectral_analysis(im)\n",
    "\n",
    "        # duplicate original spectrum in each condition to make plotting easier:\n",
    "        sf_energy, ori_energy = append_energy_results(sf_energy, ori_energy,\n",
    "                                                      res,\n",
    "                                                      letter_type=\"Undistorted\",\n",
    "                                                      letter=letter,\n",
    "                                                      flanked=flank,\n",
    "                                                      freq=freq,\n",
    "                                                      distortion=dist,\n",
    "                                                      rep=np.nan)        \n",
    "        \n",
    "        for rep in range(reps):\n",
    "            if dist == \"BPN\":\n",
    "                d_im = bex_distorted_im(im, amplitude=px_thresh, frequency=freq)\n",
    "            elif dist == \"RF\":\n",
    "                d_im = rf_distorted_im(im, amplitude=thresh, frequency=freq)\n",
    "            else:\n",
    "                raise ValueError(\"distortion not known\")\n",
    "\n",
    "#             # save images to check:\n",
    "#             if flank is \"max\":\n",
    "#                 fname = os.path.join(out_dir, \"test_ims\", \n",
    "#                                     \"{}_{}_{}_{}_{}_{}.png\".format(\n",
    "#                     dist, letter, freq, thresh, flank, rep))\n",
    "#                 io.imsave(fname, d_im)\n",
    "                \n",
    "            res = pu.image.spectral_analysis(d_im)\n",
    "            sf_energy, ori_energy = append_energy_results(sf_energy, ori_energy,\n",
    "                                                          res,\n",
    "                                                          letter_type=\"Distorted\",\n",
    "                                                          letter=letter,\n",
    "                                                          flanked=flank,\n",
    "                                                          freq=freq,\n",
    "                                                          distortion=dist,\n",
    "                                                          rep=rep)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data:\n",
    "sf_energy.to_csv(os.path.join(out_dir, \"sf_energy.csv\"))\n",
    "ori_energy.to_csv(os.path.join(out_dir, \"ori_energy.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
