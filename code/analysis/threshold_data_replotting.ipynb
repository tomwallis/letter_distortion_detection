{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replot threshold data for publication\n",
    "\n",
    "I've decided not to invest time reanalysing this data with a GLMM-style thing. The paper doesn't warrant it. Instead, I am shooting for a minimal presentation of the results. To do so, I will use Saskia's *psignifit* fits to individual conditions. \n",
    "\n",
    "In this notebook I will just replot her fit data in a nicer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psyutils as pu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pal = sns.color_palette(\"colorblind\", 2)\n",
    "pal = sns.color_palette(['#282828', '#888888'])\n",
    "sns.set_palette(pal)\n",
    "sns.palplot(pal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_dir = pu.files.project_directory('letter-distortion-detection')\n",
    "fig_dir = os.path.join(top_dir, 'figures')\n",
    "fname = os.path.join(top_dir, 'results', 'saskia_analysis', 'sensitivitydata', 'alldatasensexp1+2.csv')\n",
    "dat = pd.read_csv(fname, sep='\\t')\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove leading spaces from variable names, rename cols:\n",
    "def new_col(col):\n",
    "    # rename columns containing leading space:\n",
    "    col = col.rstrip()\n",
    "    return col.lstrip()\n",
    "\n",
    "dat.rename(columns=new_col, inplace=True)\n",
    "\n",
    "dat.rename(columns={'subject': 'Observer',\n",
    "                    'distortiontype': 'Distortion'}, \n",
    "           inplace=True)\n",
    "\n",
    "dat.loc[dat['Distortion']==' Bex', 'Distortion'] = 'BPN'\n",
    "dat.loc[dat['Distortion']==' RF', 'Distortion'] = 'RF'\n",
    "\n",
    "dat.loc[:, 'log_freq'] = np.log(dat['freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify peak tuning for BPN by fitting log Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inv_gauss_fun(x, pars):\n",
    "    peak_x, peak_y, width, amp = pars\n",
    "    gauss = np.exp(- ((x - peak_x)**2 / (2 * width**2) ))\n",
    "    return amp * (1 - gauss) + peak_y\n",
    "\n",
    "\n",
    "def error_fun(pars, x, y):\n",
    "    yhat = inv_gauss_fun(x, pars)\n",
    "    return ((y - yhat)**2).sum()  # minimise sum of squared errors\n",
    "       \n",
    "\n",
    "def expand_grid(data_dict):\n",
    "    rows = product(*data_dict.values())\n",
    "    return pd.DataFrame.from_records(rows, columns=data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 5, num=50)\n",
    "pars = [2, -3, 1, 1]\n",
    "y = inv_gauss_fun(x, pars)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over subjects, condition\n",
    "\n",
    "(I'm sure there's a way to do this with a groupby / apply operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdat = dat.loc[dat['Distortion']=='BPN', :].copy(deep=True)\n",
    "param_dat = expand_grid({'Observer': np.unique(subdat['Observer']), \n",
    "                         'flanked': np.unique(subdat['flanked'])}) \n",
    "\n",
    "for s, c in product(np.unique(subdat['Observer']), np.unique(subdat['flanked'])):\n",
    "    mask = (subdat['Observer']==s) & (subdat['flanked']==c)\n",
    "    this_dat = subdat.loc[mask, :]\n",
    "    print('Subject {}, condition {}'.format(s, c))\n",
    "    res = minimize(error_fun, [1, 0.5, 2, 2], \n",
    "                   args=(this_dat['log_freq'], np.log(this_dat['threshold'])),\n",
    "                   method='BFGS')\n",
    "    print('converged = {}'.format(res.success))\n",
    "    print(res.message)\n",
    "    \n",
    "    # save to frame:\n",
    "    param_mask = (param_dat['Observer']==s) & (param_dat['flanked']==c)\n",
    "    param_dat.loc[param_mask, 'peak_x'] = np.exp(res.x[0])\n",
    "    param_dat.loc[param_mask, 'peak_y'] = np.exp(res.x[1])\n",
    "    param_dat.loc[param_mask, 'width'] = res.x[2]\n",
    "    param_dat.loc[param_mask, 'amp'] = res.x[3]\n",
    "    \n",
    "    # generate predictions for plotting:\n",
    "    xhat = np.linspace(subdat['log_freq'].min(), subdat['log_freq'].max())\n",
    "    yhat = inv_gauss_fun(xhat, res.x)\n",
    "    pred_dat = expand_grid({'Observer': [s], \n",
    "                            'flanked': [c], \n",
    "                            'xhat': xhat})\n",
    "    pred_dat['yhat'] = yhat\n",
    "    subdat = subdat.append(pred_dat, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_wrap(x, y, lo, hi, **kwargs):\n",
    "    err = np.array([lo, hi])\n",
    "    plt.errorbar(x, y, err, **kwargs)\n",
    "    \n",
    "    \n",
    "def log_error_wrap(x, y, lo, hi, **kwargs):\n",
    "    err = np.array([np.log(y) - np.log(y - lo), np.log(y + hi) - np.log(y)])\n",
    "    plt.errorbar(x, np.log(y), err, **kwargs)\n",
    "    \n",
    "    \n",
    "def plot_preds(**kwargs):\n",
    "    # function to plot the log gauss predictions:\n",
    "    data = kwargs.pop('data')\n",
    "    plt.plot(data['xhat'], data['yhat'], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPN plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(subdat, col='Observer', hue='flanked', hue_kws={'marker': ['o', 's']}, \n",
    "#                   col_wrap=2,\n",
    "                  dropna=False,\n",
    "                  size=2, legend_out=False)\n",
    "g.map_dataframe(plot_preds, ls='-', ms=0)\n",
    "g.map(log_error_wrap, 'log_freq', 'threshold', 'threshconfi_low', 'threshconfi_high',\n",
    "      ls='')\n",
    "\n",
    "# g.set(xlabel='Frequency (c/deg)', ylabel='Threshold')\n",
    "g.set_xlabels('Frequency (c/deg)')\n",
    "g.set_ylabels('Threshold')\n",
    "\n",
    "x_labels = [1, 2, 4, 8, 16, 32]\n",
    "x_ticks = np.log(x_labels)\n",
    "g.set(xticks=x_ticks, xticklabels=x_labels)\n",
    "\n",
    "y_labels = [.01, .02, .04, .08, .16]\n",
    "y_ticks = np.log(y_labels)\n",
    "g.set(yticks=y_ticks, yticklabels=y_labels)\n",
    "\n",
    "# g.add_legend(title='')\n",
    "g.fig.subplots_adjust(hspace=0.6, wspace=0.5)\n",
    "sns.despine(trim=True, offset=5);\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_1_bpn.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot peak estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_dat.groupby(['flanked']).peak_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# difference in octaves:\n",
    "np.log2(8.69 / 6.42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.stripplot(x='flanked', y='peak_x', data=param_dat,\n",
    "                  jitter=0.05,\n",
    "#               order=['unflanked', 'flanked'],\n",
    "#               hue_order=['flanked', 'unflanked'],\n",
    "                  palette=[pal[1], pal[0]])\n",
    "\n",
    "g.set(xlabel='', ylabel='Peak frequency (c/deg)')\n",
    "sns.despine(trim=True, offset=2)\n",
    "g.set(yticks=[5, 7, 9, 11])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(3.5, 3)\n",
    "plt.savefig(os.path.join(fig_dir, 'experiment_1_bpn_peaks.pdf'), \n",
    "            bbox_inches='tight',\n",
    "            figsize=(1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export peak frequencies out for JASP analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = pd.pivot_table(param_dat, \n",
    "                     index=['Observer'], \n",
    "                     columns=['flanked'], \n",
    "                     values=['peak_x'])\n",
    "\n",
    "# rename column names (from https://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns)\n",
    "out.columns = ['_'.join(col).strip() for col in out.columns.values]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv for analysis in JASP:\n",
    "out.to_csv(os.path.join(top_dir, 'results', 'experiment_1', 'peak_estimates.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot thresholds\n",
    "subdat = dat.loc[dat['Distortion']=='RF', :]\n",
    "\n",
    "g = sns.FacetGrid(subdat, col='Observer', hue='flanked',  hue_kws={'marker': ['o', 's']}, \n",
    "#                   col_wrap=2, \n",
    "                  size=2, legend_out=False)\n",
    "g.map(log_error_wrap, 'log_freq', 'threshold', 'threshconfi_low', 'threshconfi_high',\n",
    "      ls='')\n",
    "\n",
    "# g.set(xlabel='Frequency (c/deg)', ylabel='Threshold')\n",
    "g.set_xlabels('Frequency (c / $2\\pi$)')\n",
    "g.set_ylabels('Threshold')\n",
    "\n",
    "x_labels = [1, 2, 4, 8, 16, 32]\n",
    "x_ticks = np.log(x_labels)\n",
    "g.set(xticks=x_ticks, xticklabels=x_labels)\n",
    "\n",
    "y_labels = [.01, .02, .04, .1, .2, .4]\n",
    "y_ticks = np.log(y_labels)\n",
    "g.set(yticks=y_ticks, yticklabels=y_labels)\n",
    "\n",
    "# plt.legend(title='', loc='lower right')\n",
    "g.add_legend(title='')\n",
    "g.fig.subplots_adjust(hspace=0.6, wspace=0.5)\n",
    "\n",
    "sns.despine(trim=True, offset=5);\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_1_rf.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance as a function of target letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the raw psi data:\n",
    "fname = os.path.join(top_dir, 'results', 'experiment_1', 'all_data.csv')\n",
    "# this file created by data_munging_expt_1.py\n",
    "dat = pd.read_csv(fname)\n",
    "\n",
    "# dat.loc[dat['subject']=='2', 'Observer'] = 'XXX'\n",
    "\n",
    "\n",
    "dat.loc[dat['distortion']==' bex', 'Distortion Type'] = 'BPN'\n",
    "dat.loc[dat['distortion']==' rf', 'Distortion Type'] = 'RF'\n",
    "\n",
    "# remap subject numbers to initials:\n",
    "dat.loc[dat['subject']==2, 'Observer'] = 'TW'\n",
    "dat.loc[dat['subject']==5, 'Observer'] = 'ST'\n",
    "dat.loc[dat['subject']==7, 'Observer'] = 'AM'\n",
    "dat.loc[dat['subject']==8, 'Observer'] = 'RM'\n",
    "dat.loc[dat['subject']==9, 'Observer'] = 'MF'\n",
    "\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.groupby(['targ_letter', 'distortion']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(dat['Distortion Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot('targ_letter', 'correct', hue='Distortion Type',\n",
    "                   palette=pal, data=dat,\n",
    "                   kind='point', size=3, linestyles=['', ''], legend_out=False)\n",
    "\n",
    "g.set_xlabels('Target letter')\n",
    "g.set_ylabels('Proportion correct')\n",
    "g.set(yticks=[.5, .55, .6, .65, .7, .75])\n",
    "sns.despine(trim=True, offset=0)\n",
    "g.fig.set_figwidth(3)\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_1_targ_letter.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot('targ_letter', 'correct', hue='Distortion Type', col='Observer',\n",
    "                   col_order=['AM', 'MF', 'RM', 'ST', 'TW'],\n",
    "                   col_wrap=3,\n",
    "                   palette=pal, data=dat,\n",
    "                   kind='point', size=3, linestyles=['', ''], legend_out=True)\n",
    "\n",
    "g.set_xlabels('Target letter')\n",
    "g.set_ylabels('Proportion correct')\n",
    "g.set(yticks=np.arange(.3, .9, step=.1))\n",
    "sns.despine(trim=True, offset=0)\n",
    "g.fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "g.fig.set_figwidth(6)\n",
    "g.fig.set_figheight(3.7)\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_1_targ_letter_by_subj.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "Note the labelling of the data files is \"Experiment 3\" here, because in the data collection we called each different distortion type (above) a separate experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pal = sns.color_palette(['#252525', '#636363', '#969696'])\n",
    "# pal = sns.cubehelix_palette(3, start=1, rot=1.5, light=0.6, dark=0.3, reverse=True)\n",
    "sns.set_palette(pal)\n",
    "sns.palplot(pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check trial numbers by opening and grouping my munged file\n",
    "# (produced by data_munging_expt_2.py)\n",
    "fname = os.path.join(top_dir, 'results', 'experiment_2', 'all_data.csv')\n",
    "dat = pd.read_csv(fname)\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.groupby(['experiment']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(top_dir, 'results', 'saskia_analysis', 'sensitivitydata', 'alldatasensexp3c.csv')\n",
    "dat = pd.read_csv(fname, sep='\\t')\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.rename(columns=new_col, inplace=True)\n",
    "\n",
    "dat.rename(columns={'subject': 'Observer',\n",
    "                    'distortiontype': 'Distortion',\n",
    "                    'distflanker': 'n_dist_flanks', \n",
    "                    'exp3': 'Experiment'}, \n",
    "           inplace=True)\n",
    "\n",
    "dat.loc[dat['Distortion']==' Bex', 'Distortion'] = 'BPN'\n",
    "dat.loc[dat['Distortion']==' RF', 'Distortion'] = 'RF'\n",
    "\n",
    "dat.loc[dat['Experiment']==' a', 'Experiment'] = 'a'\n",
    "dat.loc[dat['Experiment']==' b', 'Experiment'] = 'b'\n",
    "dat.loc[dat['Experiment']==' c', 'Experiment'] = 'c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPN plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_error_wrap_dataframe(x, y, lo, hi, **kwargs):\n",
    "    # needed because of hashtable error with unbalanced data.\n",
    "    data = kwargs.pop('data')\n",
    "    x = data[x].values\n",
    "    x = x.astype(np.float)\n",
    "    \n",
    "    if np.any(data['Experiment']=='b'):\n",
    "        x -= .3\n",
    "    elif np.any(data['Experiment']=='c'):\n",
    "        x += .3\n",
    "        \n",
    "    y = data[y].values\n",
    "    lo = data[lo].values\n",
    "    hi = data[hi].values\n",
    "    err = np.array([np.log(y) - np.log(y - lo), np.log(y + hi) - np.log(y)])\n",
    "    plt.errorbar(x, np.log(y), err, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot thresholds\n",
    "subdat = dat.loc[dat['Distortion']=='BPN', :]\n",
    "\n",
    "g = sns.FacetGrid(subdat, col='Observer', \n",
    "                  hue='Experiment', \n",
    "                  hue_kws={'marker': ['o', 's', 'd']}, \n",
    "                  size=2, legend_out=True)\n",
    "g.map_dataframe(log_error_wrap_dataframe, 'n_dist_flanks', 'threshold', 'threshconfi_low', 'threshconfi_high',\n",
    "      ls='')\n",
    "\n",
    "g.set(xlabel='No. distorted flankers', ylabel='Threshold')\n",
    "\n",
    "x_labels = [0, 2, 4]\n",
    "x_ticks = x_labels\n",
    "g.set(xticks=x_ticks, xticklabels=x_labels)\n",
    "g.set(xlim=(-0.2, 4.5))\n",
    "y_labels = [.02, .04, .08, .16, .32]\n",
    "y_ticks = np.log(y_labels)\n",
    "g.set(yticks=y_ticks, yticklabels=y_labels)\n",
    "\n",
    "g.add_legend()\n",
    "g.fig.subplots_adjust(hspace=0.6, wspace=1)\n",
    "sns.despine(trim=True, offset=5);\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_2_bpn.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot thresholds\n",
    "subdat = dat.loc[dat['Distortion']=='RF', :]\n",
    "\n",
    "g = sns.FacetGrid(subdat, col='Observer', \n",
    "                  hue='Experiment', \n",
    "                  hue_kws={'marker': ['o', 's', 'd']}, \n",
    "                  size=2, legend_out=True)\n",
    "g.map_dataframe(log_error_wrap_dataframe, 'n_dist_flanks', 'threshold', 'threshconfi_low', 'threshconfi_high',\n",
    "      ls='')\n",
    "\n",
    "g.set(xlabel='No. distorted flankers', ylabel='Threshold')\n",
    "\n",
    "x_labels = [0, 2, 4]\n",
    "x_ticks = x_labels\n",
    "g.set(xticks=x_ticks, xticklabels=x_labels)\n",
    "g.set(xlim=(-0.2, 4.5))\n",
    "\n",
    "y_labels = [.04, .1, .2, .4, .8]\n",
    "y_ticks = np.log(y_labels)\n",
    "g.set(yticks=y_ticks, yticklabels=y_labels)\n",
    "\n",
    "g.add_legend()\n",
    "g.fig.subplots_adjust(hspace=0.6, wspace=1)\n",
    "sns.despine(trim=True, offset=5);\n",
    "g.savefig(os.path.join(fig_dir, 'experiment_2_rf.pdf'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
